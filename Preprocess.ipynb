{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Path to the directory containing the X-ray images\n",
    "dataset_folder = \"Cleaned Images\"\n",
    "\n",
    "\n",
    "# Function to preprocess images\n",
    "def preprocess_image(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Resize the image to a consistent size (e.g., 512x512)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Normalize pixel values to the range [0, 1]\n",
    "    normalized_image = gray_image / 255.0\n",
    "    \n",
    "    # Apply Gaussian blur for noise reduction\n",
    "    blurred_image = cv2.GaussianBlur(normalized_image, (5, 5), 0)\n",
    "    \n",
    "    # Perform contrast enhancement using histogram equalization\n",
    "    enhanced_image = cv2.equalizeHist(np.uint8(blurred_image * 255))\n",
    "    \n",
    "    return enhanced_image\n",
    "\n",
    "# Function to preprocess all images in a directory (including subdirectories)\n",
    "def preprocess_images_in_directory(directory):\n",
    "    for filename in os.listdir(directory):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        if os.path.isdir(filepath):\n",
    "            # If the item is a directory, recursively call the function\n",
    "            preprocess_images_in_directory(filepath)\n",
    "        elif filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Preprocess the image\n",
    "            preprocessed_image = preprocess_image(filepath)\n",
    "            \n",
    "            # Save the preprocessed image to the preprocessed folder\n",
    "            relative_path = os.path.relpath(filepath, dataset_folder)\n",
    "            preprocessed_image_path = os.path.join(preprocessed_folder, relative_path)\n",
    "            os.makedirs(os.path.dirname(preprocessed_image_path), exist_ok=True)\n",
    "            cv2.imwrite(preprocessed_image_path, preprocessed_image)\n",
    "\n",
    "# Preprocess all images in the dataset folder (including subfolders)\n",
    "for i in os.listdir(dataset_folder):\n",
    "    preprocessed_folder = \"PreprocessedDataset\"\n",
    "    os.makedirs(preprocessed_folder, exist_ok=True)\n",
    "    preprocess_images_in_directory(dataset_folder+\"/\"+i)\n",
    "    # Create a new directory to store preprocessed images\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "dataset_folder = \"PreprocessedDataset/train\"\n",
    "\n",
    "# Function to count images in each class\n",
    "def count_images_per_class(dataset_folder):\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(dataset_folder):\n",
    "        class_path = os.path.join(dataset_folder, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            num_images = len([name for name in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, name))])\n",
    "            class_counts[class_name] = num_images\n",
    "    return class_counts\n",
    "\n",
    "# Printing number of images in each class\n",
    "class_counts = count_images_per_class(dataset_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_counts.keys(), class_counts.values(), color='skyblue')\n",
    "plt.xlabel('Severity Grading')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images in Each Class')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load train data\n",
    "train_generator = ImageDataGenerator().flow_from_directory(\n",
    "    \"PreprocessedDataset/train\",\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    batch_size=64,  # Reduced batch size\n",
    "    target_size=(224, 224),\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Concatenate data\n",
    "x = []\n",
    "y = []\n",
    "for _ in range(train_generator.__len__()):\n",
    "    batch_x, batch_y = train_generator.next()\n",
    "    x.append(batch_x)\n",
    "    y.append(batch_y)\n",
    "x = np.concatenate(x)\n",
    "y = np.concatenate(y)\n",
    "\n",
    "# Reshape data\n",
    "X_train = x.reshape(x.shape[0], -1)\n",
    "\n",
    "# Apply SMOTE\n",
    "sm = SMOTE(random_state=2)  # Reduced SMOTE batch size\n",
    "X_smote, y_smote = sm.fit_resample(X_train, y)\n",
    "\n",
    "# Save images incrementally\n",
    "train_sep_dir = 'smotefolder'\n",
    "if not os.path.exists(train_sep_dir):\n",
    "    os.mkdir(train_sep_dir)\n",
    "\n",
    "def save_images(X_smote, y_smote, train_sep_dir, start_index=0):\n",
    "    for i in range(len(X_smote)):\n",
    "        label = np.argmax(y_smote[i])  # Get index of maximum value (class label)\n",
    "        label_dir = os.path.join(train_sep_dir, str(label))\n",
    "        if not os.path.exists(label_dir):\n",
    "            os.mkdir(label_dir)\n",
    "        img = array_to_img(X_smote[i].reshape((224, 224, 3)))\n",
    "        img.save(os.path.join(label_dir, f'smote_{start_index + i}.jpg'))\n",
    "\n",
    "# Split saving into smaller batches\n",
    "batch_size = 1000\n",
    "for i in range(0, len(X_smote), batch_size):\n",
    "    save_images(X_smote[i:i+batch_size], y_smote[i:i+batch_size], train_sep_dir, start_index=i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "dataset_folder = \"smotefolder\"\n",
    "\n",
    "# Function to count images in each class\n",
    "def count_images_per_class(dataset_folder):\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(dataset_folder):\n",
    "        class_path = os.path.join(dataset_folder, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            num_images = len([name for name in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, name))])\n",
    "            class_counts[class_name] = num_images\n",
    "    return class_counts\n",
    "\n",
    "# Function to randomly oversample images in class 2\n",
    "def random_oversample_class_2(dataset_folder, oversample_ratio):\n",
    "    class_2_path = os.path.join(dataset_folder, \"2\")\n",
    "    images_class_2 = [name for name in os.listdir(class_2_path) if os.path.isfile(os.path.join(class_2_path, name))]\n",
    "    num_images_class_2 = len(images_class_2)\n",
    "    \n",
    "    # Calculate number of images to oversample for class 2\n",
    "    num_oversample = int((oversample_ratio - 1) * num_images_class_2)\n",
    "    \n",
    "    # Randomly select images to duplicate for class 2\n",
    "    images_to_duplicate = np.random.choice(images_class_2, size=num_oversample, replace=True)\n",
    "    \n",
    "    # Copy and rename duplicated images for class 2\n",
    "    for image_name in images_to_duplicate:\n",
    "        src_path = os.path.join(class_2_path, image_name)\n",
    "        dst_path = os.path.join(class_2_path, f\"oversampled_{image_name}\")\n",
    "        os.system(f\"copy {src_path} {dst_path}\")\n",
    "\n",
    "# Printing number of images in each class before oversampling\n",
    "class_counts_before = count_images_per_class(dataset_folder)\n",
    "print(\"Number of images in each class before oversampling:\")\n",
    "print(class_counts_before)\n",
    "\n",
    "# Randomly oversample class 2 (increase to 2 times)\n",
    "random_oversample_class_2(dataset_folder, oversample_ratio=2)\n",
    "\n",
    "# Printing number of images in each class after oversampling\n",
    "class_counts_after = count_images_per_class(dataset_folder)\n",
    "print(\"\\nNumber of images in each class after oversampling:\")\n",
    "print(class_counts_after)\n",
    "\n",
    "# Plotting bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(class_counts_after.keys(), class_counts_after.values(), color='skyblue')\n",
    "plt.xlabel('Severity Grading')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.title('Number of Images in Each Class after Random Oversampling for Class 2')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  UNDERSAMPLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Define paths to your original dataset\n",
    "original_data_dir = 'PreprocessedDataset/train'\n",
    "downsampled_data_dir = 'DownsampledDataset2'\n",
    "\n",
    "# Define the number of samples you want to keep for class 2\n",
    "desired_samples_class_2 = 500\n",
    "\n",
    "# Create the downsampled data directory if it doesn't exist\n",
    "if not os.path.exists(downsampled_data_dir):\n",
    "    os.makedirs(downsampled_data_dir)\n",
    "\n",
    "# Define classes\n",
    "classes = ['0', '1', '2']\n",
    "\n",
    "# Define the downsampling ratio\n",
    "downsampling_ratio = desired_samples_class_2 / 2000.0  # Assuming 2000 samples initially for classes 0 and 1\n",
    "\n",
    "# Loop through each class\n",
    "for class_name in classes:\n",
    "    # Create the subdirectory for the current class in the downsampled data directory\n",
    "    class_dir = os.path.join(downsampled_data_dir, class_name)\n",
    "    os.makedirs(class_dir, exist_ok=True)\n",
    "    \n",
    "    # Determine the number of samples to keep for the current class\n",
    "    if class_name == '2':\n",
    "        desired_samples = desired_samples_class_2\n",
    "    else:\n",
    "        desired_samples = int(2000 * downsampling_ratio)\n",
    "    \n",
    "    # Get the list of file names for the current class\n",
    "    files = os.listdir(os.path.join(original_data_dir, class_name))\n",
    "    \n",
    "    # Randomly select a subset of files\n",
    "    selected_files = random.sample(files, desired_samples)\n",
    "    \n",
    "    # Copy the selected files to the downsampled data directory\n",
    "    for file in selected_files:\n",
    "        src = os.path.join(original_data_dir, class_name, file)\n",
    "        dst = os.path.join(class_dir, file)\n",
    "        shutil.copy(src, dst)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
